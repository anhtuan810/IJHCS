Public speaking concerns not only what, but also how information is delivered, in terms of nonverbal behaviors. Our research aims to specify the nonverbal cues that affect a presentation. It was conducted by collecting a database of 39 presentations include seven males, four females. The database was recorded from a class of public speaking skills using a regular camera and a Microsoft Kinect simultaneously. An expert in public speaking was asked to watch the videos and then point out the behaviors that were important to the presentations. The software Noldus Observer XT was employed for video annotation and statistics. The behaviors are categorized into six channels: body posture, voice, eye contact, facial expression, whole body movement and hand gesture. The observation served as the ground truth for developing an intelligence system that can interpret nonverbal behaviors, thus can help public speakers to improve their skills.